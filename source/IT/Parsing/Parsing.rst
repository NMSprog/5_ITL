*******
Парсинг
*******

.. attention:: Парсинг может привести к блокировке пользователя или его IP-адреса, а в редких случаях — к юридическим последствиям. Кража контента, Нагрузка на сервер

.. important:: Вместо парсинга часто лучше использовать официальные API, если они доступны.

.. important:: Или Headless браузер — это веб-браузер, который работает без графического интерфейса пользователя. Проще говоря, это браузер, который выполняет все те же функции, что и обычный браузер (например, Google Chrome или Firefox), но без отображения окна.

**Минусы:**

1. Изменения в структуре сайта - требует регулярных обновлений кода
2. Многие сайты используют JavaScript для динамической загрузки данных,что может затруднять их парсинг стандартными инструментами.
3. CAPTCHA и защиты от ботов:
4. При парсинге сайтов существует риск получения вредоносного кода, особенно если данные парсятся с незащищенных или подозрительных источников.
5. Обработка больших объемов данных: Парсинг больших объемов данных может требовать значительных ресурсов, как по времени, так и по вычислительным мощностям.
6. Медленная скорость обновлений: Сайты могут обновляться слишком часто, и парсинг может быть неэффективным способом получения данных по сравнению с использованием API.

**Как сайты обнаруживают парсинг?**

1. Аномальное количество запросов: Сайты отслеживают количество запросов от каждого пользователя или IP-адреса. Если запросы поступают слишком часто или в большом количестве, это может быть признаком автоматического парсинга. Пример: обычный пользователь открывает страницу раз в несколько секунд или минут, тогда как бот может делать десятки запросов в секунду.
2. Отсутствие JavaScript-активности: Многие современные сайты полагаются на выполнение JavaScript для загрузки контента или отслеживания активности пользователя. Если браузер не выполняет JavaScript (как это бывает при стандартном парсинге), сайт может распознать подозрительное поведение.
3. Пользовательские агенты (User Agent): В HTTP-запросах браузеры отправляют строку User-Agent, которая идентифицирует браузер, его версию и операционную систему. Если парсинг выполняется стандартными библиотеками, такими как requests в Python, строка User-Agent будет отличаться от реальных браузеров. Это может сигнализировать сайту, что запрос идет не от пользователя, а от программы.
4. Отсутствие действий пользователя: Сайты могут отслеживать такие действия пользователя, как движение мыши, клики и скроллинг. Если таких действий нет, это может быть индикатором автоматизированного парсинга.
5. Использование CAPTCHA: Когда сайт подозревает автоматические запросы, он может показать CAPTCHA для проверки, что запросы делает реальный человек. Парсеры не могут пройти такие проверки без специальных методов.
6. Механизмы защиты от ботов (например, Cloudflare): Некоторые сайты используют сервисы для защиты от ботов, такие как Cloudflare, которые анализируют запросы, проверяют их на подозрительное поведение и могут блокировать запросы, которые выглядят как парсинг.
7. IP-блокировки: Если с одного IP-адреса поступает слишком много запросов, сайт может временно или навсегда заблокировать этот IP, чтобы предотвратить дальнейший парсинг.

::

    # импорт стандартных библиотек
    import csv # модуль для работы с CSV-файлами
    import json # модуль необходимый для работы с JSON-данными.
    import random # модуль используемый для генерации случайных чисел.

    from time import sleep # функцию sleep из модуля time, чтобы задерживать выполнение программы.

    # импорт стороних библиотек
    import requests # используется для выполнения HTTP-запросов (GET, POST и т.д.).
    from bs4 import BeautifulSoup # импортирует класс BeautifulSoup из библиотеки bs4 для парсинга HTML-кода.

::

    # Устанавливает переменную url, содержащую ссылку на веб-страницу для дальнейшего запроса.
    url = 'https://health-diet.ru/table_calorie/?utm_source=leftMenu&utm_medium=table_calorie'

::

    # Создание словаря headers с заголовками запроса. 
    # Accept: "*/*" — клиент принимает любые типы данных.
    # User-Agent — идентифицирует клиент как браузер Chrome на Windows.

    headers = {
        "Accept": "*/*",
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.3"

    }
